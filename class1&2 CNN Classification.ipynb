{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 1 - CNN basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 실습 축약형 \n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name = 'input') # 인풋을 784개의 사이즈로 설정 \n",
    "h = tf.layers.dense(inputs = x, units = 1200, name = 'fc') # 아웃풋이 1200개로 설정\n",
    "#바이어스는 디폴트로 설정되어있으며 따로 설정되어있음 'fc/kernel:0' 와 'fc/bias:0' 가 바이어스 설정내용이며 \n",
    "# 미리 바이어스는 0으로 설정되어있고 아웃풋 개수만큼 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fc/kernel:0' shape=(784, 1200) dtype=float32_ref>\n",
      "<tf.Variable 'fc/bias:0' shape=(1200,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "vars = tf.trainable_variables()\n",
    "\n",
    "for var in vars:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'numpy.version' from 'C:\\\\Users\\\\User\\\\Anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\version.py'>\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print (np.version)\n",
    "print(np.version.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### 두번째실습 : MNIST dataset\n",
    "## 데이터 사이즈 작음 print(len(mnist.train.images)) = 트레이닝 5만장 , 테스트 1만장정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 변수 정의 \n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 15\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "IMAGE_SIZE = 28*28*1\n",
    "CLASSES = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sess = tf.Session() 무엇? \n",
    "##  단순히 선언만 되어있는 변수 shape에 변수들을 메모리에 올리는 작업이 Session \n",
    "## 나의 컴 GPU 에 내가 선언한 변수들을 GPU 에 선언하여 하나의 세션으로 차지하여 변수를 올려서 사용\n",
    "# sess.run(tf.global_variables_initializer()) 은 내가 설정한 세션에서 param을 넣어서 run 실행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## learning rate 의 경우 총 epoch = 10 번 인경우 훈련 50% (에포크 5번 했을때) 1e-2에서 1e-3으로 줄이는 것으로 할수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 2 about CNN, ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch normalization\n",
    "relu 의 입력값이 다 양수인경우 \n",
    "활성함수를 쓰는 의미가 없음 \n",
    "입력값을 모두 스케일링하고 쉬프트 하여 \n",
    "배치에 들어간 입력값들을 같은 사이즈로 음수값도 생기게끔 함. 그러면 RELU를 썻을때 레이어 깊이에 상관없이 더 트레이닝이 더 잘 되고 음수인 입력값들을 날림 그래서 더 트레이닝이 잘됨\n",
    "\n",
    "skip connection 입력값\n",
    "레이어가 깊어져도 입력값의 특성을 계속 가지게 됨 - 입력값의 피쳐특징을 그나마 계속 가져갈수 있게 됨 - 풀링하면(또는 스트라이드 2로 해서(풀링과 스트라이드 크게 사용하는것과 효과가 같음 ) 사이즈가 달라져서 안쓸때는 입력값의 사이즈가 달라지게됨\n",
    "\n",
    "\n",
    "레즈넷은 cnn 에서 batch normalization & skip connection을 같이 사용하고 마지막으로 \n",
    "global average pooling을 사용 (global max pooling과 비교됨) 왜 사용됨?? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch normalization\n",
    "relu 의 입력값이 다 양수인경우 \n",
    "활성함수를 쓰는 의미가 없음 \n",
    "입력값을 모두 스케일링하고 쉬프트 하여 \n",
    "배치에 들어간 입력값들을 같은 사이즈로 음수값도 생기게끔 함. 그러면 RELU를 썻을때 레이어 깊이에 상관없이 더 트레이닝이 더 잘 되고 음수인 입력값들을 날림 그래서 더 트레이닝이 잘됨\n",
    "\n",
    "skip connection 입력값\n",
    "레이어가 깊어져도 입력값의 특성을 계속 가지게 됨 - 입력값의 피쳐특징을 그나마 계속 가져갈수 있게 됨 - 풀링하면(또는 스트라이드 2로 해서(풀링과 스트라이드 크게 사용하는것과 효과가 같음 ) 사이즈가 달라져서 안쓸때는 입력값의 사이즈가 달라지게됨\n",
    "\n",
    "\n",
    "레즈넷은 cnn 에서 batch normalization & skip connection을 같이 사용하고 마지막으로 \n",
    "global average pooling을 사용 (global max pooling과 비교됨) 왜 사용됨?? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
